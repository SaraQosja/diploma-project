// backend/services/aiService.js 
const fetch = require('node-fetch');
const aiConfig = require('../config/aiConfig');

class AIService {
  constructor() {
    this.systemPrompt = aiConfig.systemPrompt;
    this.hasOpenAI = !!aiConfig.openai.apiKey && aiConfig.openai.apiKey !== 'your_openai_key_here';
    console.log('ğŸ¤– AIService initialized');
  }

  async generateResponse(userMessage, conversationHistory = []) {
    try {
      console.log(`ğŸ¤– AI Request: "${userMessage.substring(0, 50)}..."`);
      
     
      if (process.env.GROQ_API_KEY) {
        try {
          console.log('ğŸš€ Using Groq AI...');
          const response = await this.getGroqResponse(userMessage, conversationHistory);
          console.log('âœ… Real Groq AI response received');
          return response;
        } catch (error) {
          console.log('âŒ Groq AI failed:', error.message);
        }} 
      if (this.hasOpenAI) {
        try {
          console.log('ğŸš€ Using OpenAI...');
          const response = await this.getOpenAIResponse(userMessage, conversationHistory);
          console.log('âœ… Real OpenAI response received');
          return response;
        } catch (error) {
          console.log('âŒ OpenAI failed:', error.message);
        }
      }
      try {
        console.log('ğŸš€ Using HuggingFace AI as backup...');
        const response = await this.getHuggingFaceResponse(userMessage, conversationHistory);
        console.log('âœ… HuggingFace AI response received');
        return response;
      } catch (error) {
        console.log('âŒ HuggingFace failed:', error.message);
      } 
      console.log('ğŸ  Using intelligent fallback...');
      return this.getIntelligentFallback(userMessage, conversationHistory);
      
    } catch (error) {
      console.error('âŒ AI Service Error:', error.message);
      return this.getIntelligentFallback(userMessage, conversationHistory);
    }
  }

  async getGroqResponse(userMessage, conversationHistory) {
   
    const formattedHistory = conversationHistory.map(msg => ({
      role: msg.sender === 'user' ? 'user' : 'assistant',
      content: msg.text
    }));

    const messages = [
      { role: 'system', content: this.systemPrompt },
      ...formattedHistory.slice(-6), 
      { role: 'user', content: userMessage }
    ];

    console.log('ğŸ“¤ Sending to Groq AI API...');

    const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.GROQ_API_KEY}`
      },
      body: JSON.stringify({
     model: 'llama-3.1-8b-instant',
        messages: messages,
        max_tokens: 1500,
        temperature: 0.7,
        top_p: 0.9
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error(`ğŸš¨ Groq API Error ${response.status}:`, errorText);
      
      if (response.status === 401) {
        throw new Error('Groq API key Ã«shtÃ« i pavlefshÃ«m');
      } else if (response.status === 429) {
        throw new Error('Groq rate limit - provo pÃ«rsÃ«ri pas pak');
      } else {
        throw new Error(`Groq API error: ${response.status} - ${errorText}`);
      }
    }

    const data = await response.json();
    
    if (!data.choices || !data.choices[0] || !data.choices[0].message) {
      throw new Error('Groq AI pÃ«rgjigje e pavlefshme');
    }

    const aiResponse = data.choices[0].message.content.trim();
    console.log('ğŸ¤– Real AI Response:', aiResponse.substring(0, 100) + '...');
    
    return aiResponse;
  }

  async getOpenAIResponse(userMessage, conversationHistory) {
    const messages = [
      { role: 'system', content: this.systemPrompt },
      ...conversationHistory.slice(-8),
      { role: 'user', content: userMessage }
    ];

    const requestBody = {
      model: aiConfig.openai.model,
      messages: messages,
      max_tokens: aiConfig.openai.maxTokens,
      temperature: aiConfig.openai.temperature,
      presence_penalty: 0.3,
      frequency_penalty: 0.3
    };

    console.log(`ğŸ“¤ Sending to OpenAI: ${messages.length} messages`);

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${aiConfig.openai.apiKey}`
      },
      body: JSON.stringify(requestBody)
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error(`ğŸš¨ OpenAI API Error ${response.status}:`, errorText);
      
      if (response.status === 401) {
        throw new Error('OpenAI API key Ã«shtÃ« i pavlefshÃ«m');
      } else if (response.status === 429) {
        throw new Error('OpenAI rate limit - ka mbaruar quota');
      } else if (response.status === 402) {
        throw new Error('OpenAI account ka probleme me pagesÃ«n');
      } else {
        throw new Error(`OpenAI API error: ${response.status}`);
      }
    }

    const data = await response.json();
    
    if (!data.choices || !data.choices[0] || !data.choices[0].message) {
      throw new Error('OpenAI pÃ«rgjigje e pavlefshme');
    }

    return data.choices[0].message.content.trim();
  }

  async getHuggingFaceResponse(userMessage, conversationHistory) {
    let contextPrompt = this.systemPrompt + '\n\n';
    
    if (conversationHistory.length > 0) {
      contextPrompt += 'Historia e bisedÃ«s:\n';
      conversationHistory.slice(-3).forEach(msg => {
        const role = msg.sender === 'user' ? 'PÃ«rdoruesi' : 'Asistenti';
        contextPrompt += `${role}: ${msg.text}\n`;
      });
    }
    
    contextPrompt += `\nPÃ«rdoruesi: ${userMessage}\nAsistenti:`;

    const response = await fetch(
      'https://api-inference.huggingface.co/models/microsoft/DialoGPT-large',
      {
        headers: {
          'Authorization': `Bearer hf_demo`,
          'Content-Type': 'application/json'
        },
        method: 'POST',
        body: JSON.stringify({
          inputs: contextPrompt,
          parameters: {
            max_length: 300,
            temperature: 0.7,
            do_sample: true,
            top_p: 0.9
          }
        })
      }
    );

    if (!response.ok) {
      throw new Error(`HuggingFace API error: ${response.status}`);
    }

    const result = await response.json();
    
    if (result[0]?.generated_text) {
      const fullText = result[0].generated_text;
      const assistantResponse = fullText.split('Asistenti:').pop().trim();
      return this.adaptToAlbanianContext(assistantResponse, userMessage);
    }
    
    throw new Error('HuggingFace response failed');
  }

  getIntelligentFallback(userMessage, conversationHistory) {
    const lowerMessage = userMessage.toLowerCase();
    const recentContext = conversationHistory.slice(-3).map(msg => msg.text.toLowerCase()).join(' ');
    
    if (lowerMessage.includes('mjekÃ«si') || recentContext.includes('mjekÃ«si')) {
      return `PÃ«r mjekÃ«si nÃ« ShqipÃ«ri, mesatarja e kÃ«rkuar Ã«shtÃ« zakonisht 9.0-9.5. Universiteti i TiranÃ«s ka fakultetin mÃ« tÃ« vjetÃ«r, ndÃ«rsa AURAM dhe UET janÃ« alternativa private. Procesi i pranimit Ã«shtÃ« shumÃ« konkurrues dhe kÃ«rkon pÃ«rgatitje tÃ« mirÃ« pÃ«r provimin e shtetit.

A doni informacione pÃ«r procesin e aplikimit ose kostot e studimit?`;
    }
    
    if (lowerMessage.includes('inxhinieri') || lowerMessage.includes('informatik')) {
      return `Inxhinieria e InformatikÃ«s ofron mundÃ«si tÃ« shkÃ«lqyera pune nÃ« ShqipÃ«ri:

ğŸ’¼ **Pozicione pune:**
â€¢ Zhvillues Software (40,000-80,000 lekÃ«/muaj)
â€¢ Sistem Administrator (35,000-60,000 lekÃ«/muaj)
â€¢ Data Scientist (50,000-90,000 lekÃ«/muaj)
â€¢ Cybersecurity Specialist (45,000-75,000 lekÃ«/muaj)

ğŸ¢ **Kompani tÃ« njohura:** Exelixis, Albania Telecom, Vodafone, dhe shumÃ« startup.

ğŸ“ **Universitete tÃ« mira:** Universiteti Politeknik dhe UET kanÃ« programet mÃ« tÃ« forta.

A doni tÃ« dini pÃ«r specializimet ose procesin e pranimit?`;
    }
    
    if (lowerMessage.includes('mesatare') || lowerMessage.includes('nota')) {
      return `Mesataret e pranuara variojnÃ« sipas universitetit dhe drejtimit:

ğŸ“Š **Universitete Publike:**
â€¢ MjekÃ«si: 9.0-9.5
â€¢ Inxhinieri Informatike: 8.0-8.5  
â€¢ Ekonomi/Biznes: 7.5-8.0
â€¢ DrejtÃ«si: 8.0-8.5
â€¢ Arte: 7.0-7.5

ğŸ¢ **Universitete Private:**
â€¢ Kritere mÃ« fleksibÃ«l (7.0-8.5)
â€¢ KostojnÃ« 150,000-400,000 lekÃ«/vit
â€¢ Shpesh kanÃ« teste pranimi tÃ« veÃ§anta

A keni menduar pÃ«r ndonjÃ« drejtim specifik?`;
    }
    
    if (lowerMessage.includes('universitet') || lowerMessage.includes('studim')) {
      return `Universitetet kryesore nÃ« ShqipÃ«ri:

ğŸ›ï¸ **Universitete Publike:**
â€¢ **UT (Universiteti i TiranÃ«s)** - mÃ« i madhi, traditional, shumÃ« fakultete
â€¢ **Universiteti Politeknik** - excellent pÃ«r inxhinieri dhe arkitekturÃ«
â€¢ **Universiteti BujqÃ«sor** - specializuar nÃ« bujqÃ«si dhe veterinari

ğŸ¢ **Universitete Private:**  
â€¢ **UET** - modern, teknologji, programe nÃ« anglisht
â€¢ **AURAM** - mjekÃ«si dhe shÃ«ndetÃ«si
â€¢ **Universiteti Kristal** - biznes dhe drejtÃ«si

Ã‡farÃ« drejtime ju interesojnÃ« mÃ« shumÃ«?`;
    }
    
    if (lowerMessage.includes('pse') || lowerMessage.length < 10) {
      return `ShÃ«rbimet AI janÃ« pÃ«rkohÃ«sisht tÃ« kufizuara, por mund t'ju ndihmoj me informacione pÃ«r universitetet dhe karrierÃ«n nÃ« ShqipÃ«ri. 

A mund tÃ« jeni mÃ« specifik me pyetjen tuaj? PÃ«r shembull:
â€¢ "Cili universitet Ã«shtÃ« mÃ« i mirÃ« pÃ«r..."
â€¢ "Sa Ã«shtÃ« mesatarja pÃ«r..."
â€¢ "Ã‡farÃ« pune mund tÃ« gjej me..."`;
    }
    
    return `Si CareerBot pÃ«r studentÃ«t nÃ« ShqipÃ«ri, mund t'ju ndihmoj me:

ğŸ“š **Informacione pÃ«r universitete** (publike dhe private)
ğŸ¯ **Planifikim karriere** dhe orientim profesional  
ğŸ“ **KÃ«shilla pÃ«r CV** dhe aplikime
ğŸ“Š **Mesatare dhe kritere** pranimi
ğŸ’¼ **MundÃ«si pune** pÃ«r Ã§do drejtim
ğŸ’° **Kosto studimi** dhe bursa

Ã‡farÃ« ju intereson mÃ« shumÃ«?`;
  }

  adaptToAlbanianContext(response, originalMessage) {
    const adaptations = {
      'university': 'universitet',
      'college': 'fakultet',
      'career': 'karrierÃ«',
      'job': 'punÃ«',
      'study': 'studim',
      'student': 'student',
      'education': 'arsim',
      'degree': 'diplomÃ«'
    };
    
    let adapted = response;
    for (const [eng, alb] of Object.entries(adaptations)) {
      adapted = adapted.replace(new RegExp(eng, 'gi'), alb);
    }
    

    if (originalMessage.toLowerCase().includes('universitet')) {
      adapted += '\n\nPÃ«r informacione mÃ« tÃ« detajuara pÃ«r ndonjÃ« universitet specifik, pyetni lirisht!';
    }
    
    return adapted;
  }

  async testConnection() {
    const results = {
      groq: false,
      openai: false,
      huggingface: false,
      timestamp: new Date()
    };

    if (process.env.GROQ_API_KEY) {
      try {
        await this.getGroqResponse('Test', []);
        results.groq = true;
      } catch (error) {
        console.log('Groq test failed:', error.message);
      }
    }


    if (this.hasOpenAI) {
      try {
        await this.getOpenAIResponse('Test', []);
        results.openai = true;
      } catch (error) {
        console.log('OpenAI test failed:', error.message);
      }
    }

   
    try {
      await this.getHuggingFaceResponse('Test', []);
      results.huggingface = true;
    } catch (error) {
      console.log('HuggingFace test failed:', error.message);
    }

    return results;
  }

  getServiceStatus() {
    return {
      groq: {
        configured: !!process.env.GROQ_API_KEY,
        model: 'llama3-70b-8192'
      },
      openai: {
        configured: this.hasOpenAI,
        model: aiConfig.openai.model
      },
      huggingface: {
        configured: true,
        model: 'DialoGPT-large'
      },
      fallback: {
        enabled: true,
        intelligent: true
      }
    };
  }
}

const aiServiceInstance = new AIService();
module.exports = aiServiceInstance;